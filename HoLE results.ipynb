{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last update: 26 November 2018\n",
    "# \n",
    "# This code create True MBSE dataset\n",
    "# \n",
    "# Inputs: \n",
    "# \t\t\tNone\n",
    "# Outputs:\n",
    "#\t\t\ttrue.csv : List of true pair of nodes, \n",
    "#\t\t\t\t\t   link type and target in format: [entity_a, entity_b, relation, target]\n",
    "####################################################################################################\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set parameters\n",
    "Dimension = 100\n",
    "\n",
    "# Targe values\n",
    "true = 1\n",
    "\n",
    "# Big nodes\n",
    "RequerimentType = 0\n",
    "TestCaseType = 100\n",
    "SMT = 200\n",
    "ProjectType = 300\n",
    "\n",
    "#Relation type\n",
    "instanceOf = 0\n",
    "verifiedBy = 1\n",
    "using = 2\n",
    "belongsTo = 3\n",
    "\n",
    "def Generate_True_Graph():\n",
    "\t''' Function to create all true links '''\n",
    "\n",
    "\tgraph = []\n",
    "\tfor requeriment in range(RequerimentType + 1, Dimension):\n",
    "\t    #[requirement[1-Dimension], RequirementType0, Relation = 0]\n",
    "\t    graph.append([requeriment, RequerimentType, instanceOf])\n",
    "\t    \n",
    "\t    #[requirement[1-Dimension], TestCase[1-Dimension], Relation = 1]\n",
    "\t    graph.append([requeriment, requeriment + TestCaseType, verifiedBy])\n",
    "\t    \n",
    "\t    #[requirement[1-Dimension], Proyect[1-Dimesion], Relation = 3]\n",
    "\t    graph.append([requeriment, requeriment + ProjectType, belongsTo])\n",
    "\t    \n",
    "\tfor testcase in range(TestCaseType + 1, TestCaseType + Dimension):\n",
    "\t    #[testcase[1-Dimension], TestCaseType0, Relation = 0]\n",
    "\t    graph.append([testcase, TestCaseType, instanceOf])\n",
    "\t    \n",
    "\t    #[testcase[1-Dimension], SM[1-Dimension], Relation = 2]\n",
    "\t    graph.append([testcase, testcase + (SMT - Dimension), using])\n",
    "\t    \n",
    "\t    #[testcase[1-Dimension], TestCaseType0, Relation = 3]\n",
    "\t    graph.append([testcase, testcase + (ProjectType - Dimension), belongsTo])\n",
    "\t    \n",
    "\tfor sm in range(SMT + 1, SMT + Dimension):\n",
    "\t    #[sm[1-Dimension], SMT, Relation = 0]\n",
    "\t    graph.append([sm, SMT, instanceOf])\n",
    "\t    \n",
    "\t    #[sm[1-Dimension], Proyect[1-Dimension], Relation = 3]\n",
    "\t    graph.append([sm, sm + Dimension, belongsTo])\n",
    "\n",
    "\tfor project in range(ProjectType + 1, ProjectType + Dimension):\n",
    "\t    #[project[1-Dimension], ProjectType, Relation = 0]\n",
    "\t    graph.append([project, ProjectType, instanceOf])\n",
    "\n",
    "\treturn graph\n",
    "\n",
    "\n",
    "def main():\n",
    "\t''' Principal function '''\n",
    "\n",
    "\t# Call for Postive and Negative graph\n",
    "\tpositive_graph = Generate_True_Graph()\n",
    "\n",
    "\t# Transform into a pandas dataframe\n",
    "\ttrue = pd.DataFrame(positive_graph, columns=['entity_a', 'entity_b', 'relation'])\n",
    "\t\n",
    "\t# Save data\n",
    "\ttrue.to_csv('./Data/true.csv',index = False)\n",
    "\n",
    "\treturn 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique entity_a : 396\n",
      "Total unique entity_b : 301\n",
      "Total unique entities : 400\n",
      "Total unique relations : 4\n",
      "Total unique entity_a in train dataset : 205\n",
      "Total unique entity_b in train dataset : 141\n",
      "Total unique entities in train dataset : 282\n"
     ]
    }
   ],
   "source": [
    "# Last update: 26 November\n",
    "# \n",
    "# Author: Shaurya Shubham\n",
    "# This code load the true graph and transform\n",
    "# into train, valid and to_use datasets.\n",
    "#\n",
    "# inputs:\n",
    "# true.csv\n",
    "\n",
    "#\n",
    "# outpus:\n",
    "# train.csv\n",
    "# valid.csv\n",
    "# to_use.csv\n",
    "# edges.csv\n",
    "####################################################################################\n",
    "\n",
    "# Load libraries\n",
    "import pandas as pd # To handle dataframes\n",
    "from sklearn.model_selection import train_test_split # to split the datasets\n",
    "\n",
    "\n",
    "def Edges_Generation(true_graph):\n",
    "    ''' Function to generate edges from the true graph '''\n",
    "\n",
    "    edges = []\n",
    "    for element in true_graph.iterrows():\n",
    "        edges.append([element[1]['entity_a'],element[1]['entity_b'],element[1]['relation']])\n",
    "\n",
    "    # Saving data\n",
    "    df = pd.DataFrame(edges,columns=['entity_a', 'entity_b','relation'])\n",
    "    df.to_csv('./Data/edges.csv',index= False)\n",
    "\n",
    "def Generate_Train_Valid_Use(true_graph):\n",
    "    ''' Function to generate train, valid and to_use datasets '''\n",
    "    \n",
    "    # Randomization of true\n",
    "    true_graph = true_graph.sample(frac=1).reset_index(drop = True)\n",
    "    \n",
    "    # print some stats\n",
    "    print 'Total unique entity_a : {}'.format(len(true_graph['entity_a'].unique().tolist()))\n",
    "    print 'Total unique entity_b : {}'.format(len(true_graph['entity_b'].unique().tolist()))\n",
    "    print 'Total unique entities : {}'.format(len(list(set(true_graph['entity_a'].unique().tolist() + true_graph['entity_b'].unique().tolist()))))\n",
    "    print 'Total unique relations : {}'.format(len(true_graph['relation'].unique().tolist()))\n",
    "\n",
    "\t# Splitting true_graph into 3 pieces: true_train, true_valid, true_to_use\n",
    "    train, valid_test = train_test_split(true_graph,test_size =0.7, random_state =1) # split the data into train and (test_vaidation)\n",
    "    \n",
    "    # print train dataset stats to see whether we are missing any entities or not\n",
    "    print 'Total unique entity_a in train dataset : {}'.format(len(train['entity_a'].unique().tolist()))\n",
    "    print 'Total unique entity_b in train dataset : {}'.format(len(train['entity_b'].unique().tolist()))\n",
    "    print 'Total unique entities in train dataset : {}'.format(len(list(set(train['entity_a'].unique().tolist() + train['entity_b'].unique().tolist()))))\n",
    "    \n",
    "    unique_train_entities =list(set(train['entity_a'].unique().tolist() + train['entity_b'].unique().tolist()))\n",
    "    unique_true_graph_entities = d =list(set(true_graph['entity_a'].unique().tolist() + true_graph['entity_b'].unique().tolist()))\n",
    "    missing_entities_in_train =  set(unique_true_graph_entities) -set(unique_train_entities)\n",
    "    \n",
    "    train_extra = valid_test[valid_test.entity_b.isin(missing_entities_in_train)] # get the missing entities from entity_b to get embedding for all entities\n",
    "    train = pd.concat([train,train_extra]) # making the complete train datset with all entities\n",
    "    train = train.reset_index(drop = True)\n",
    "    train.to_csv('./Data/train.csv',index=False)\n",
    "    \n",
    "    valid_test = valid_test[~valid_test.entity_b.isin(missing_entities_in_train)] # remove the train data which we added to train dataset by using train_extra\n",
    "    \n",
    "    valid,test = train_test_split(valid_test,test_size =0.75, random_state =1) # split the data into valid and test(to_use)\n",
    "    valid.to_csv('./Data/valid.csv',index=False)\n",
    "    test.to_csv('./Data/to_use.csv',index=False)\n",
    "\n",
    "\n",
    "def main():\n",
    "    ''' Principal function '''\n",
    "    true_graph = pd.read_csv('./Data/true.csv')\n",
    "    Generate_Train_Valid_Use(true_graph)\n",
    "    Edges_Generation(true_graph)\n",
    "    return 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = pd.read_csv('./Data/train.csv')\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Last update: 26 November 2018\n",
    "# \n",
    "# Author: Shaurya Shubham\n",
    "# This code train the link prediction model by using HoLE and evaluate it\n",
    "# \n",
    "# Inputs:\n",
    "#     edges.csv : Dataset to create negative sample\n",
    "#     train.csv : Dataset to train the model\n",
    "# Outputs:\n",
    "#     Statistics:\n",
    "#        * About trainig\n",
    "#        * About validation\n",
    "#        * About the use of the model\n",
    "#        * About Axel format\n",
    "####################################################################################################\n",
    "\n",
    "# Loading Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from numpy.fft import fft, ifft\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from random import uniform\n",
    "\n",
    "true_data = pd.read_csv('./Data/edges.csv')\n",
    "Total_Entities = 400\n",
    "Total_Relations = 4\n",
    "Batch_Size = 2\n",
    "Num_Neg_Sample = 40\n",
    "\n",
    "# Function to create positive and negative samples\n",
    "def positive(fact):\n",
    "\n",
    "    #print fact\n",
    "    entity_a, relation, entity_b = fact['entity_a'], fact['relation'], fact['entity_b']\n",
    "    entity_a_id = Variable(torch.LongTensor([entity_a]))#.view(1, -1)\n",
    "    entity_b_id = Variable(torch.LongTensor([entity_b]))#.view(1, -1)\n",
    "    relation_id = Variable(torch.LongTensor([relation]))#.view(1, -1)\n",
    "    target = Variable(torch.LongTensor([1])).view(1, -1)\n",
    "    return [entity_a_id,entity_b_id,relation_id,target]\n",
    "    \n",
    "def negative(triplet,num_neg_triplets=1):\n",
    "    #training triplets with either the head or tail replaced by a random entity (but not both at the same time)\n",
    "    # Sample until we find an invalid fact\n",
    "    corrupted_triplets = []\n",
    "    num_neg_count = 0\n",
    "    while num_neg_count < num_neg_triplets:\n",
    "        i = uniform(-1, 1)\n",
    "        if i < 0:\n",
    "            while True:\n",
    "                entity_a = random.randint(0, Total_Entities - 1)\n",
    "                #relation = random.randint(0, Total_Relations - 1)\n",
    "                #entity_b = random.randint(0, Total_Entities - 1)\n",
    "                rule = {'entity_a':[entity_a],'entity_b':[triplet[1]],'relation':[triplet[2]]}\n",
    "                if len(list(true_data.index[true_data.isin(rule).all(1)].values)) == 0:\n",
    "                    if [[entity_a,triplet[1],triplet[2]]] not in corrupted_triplets:\n",
    "                        target = Variable(torch.LongTensor([0])).view(1, -1)\n",
    "                        corrupted_triplets.append([Variable(torch.LongTensor([entity_a])),triplet[1],triplet[2],target])\n",
    "                        num_neg_count+=1\n",
    "                        break\n",
    "        if i > 0:\n",
    "            while True:\n",
    "                entity_b = random.randint(0, Total_Entities - 1)\n",
    "                #relation = random.randint(0, Total_Relations - 1)\n",
    "                #entity_b = random.randint(0, Total_Entities - 1)\n",
    "                rule = {'entity_a':[triplet[0]],'entity_b':[entity_b],'relation':[triplet[2]]}\n",
    "                if len(list(true_data.index[true_data.isin(rule).all(1)].values)) == 0:\n",
    "                    if [[triplet[0],entity_b,triplet[2]]] not in corrupted_triplets:\n",
    "                        target = Variable(torch.LongTensor([0])).view(1, -1)\n",
    "                        corrupted_triplets.append([triplet[0],Variable(torch.LongTensor([entity_b])),triplet[2],target])\n",
    "                        num_neg_count+=1\n",
    "                        break\n",
    "\n",
    "    return corrupted_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom Dataloader\n",
    "class CustomDataset():\n",
    "    \n",
    "    def __init__(self,filepath):\n",
    "        self.data = pd.read_csv(filepath, delimiter=',')\n",
    "        self.data.dropna(inplace=True)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        sample = {}\n",
    "        sample['pos'] = positive(self.data.iloc[index])\n",
    "        #sample['neg'] = negative()\n",
    "        sample['neg'] = negative(sample['pos'],Num_Neg_Sample)\n",
    "        #for i in range(Num_Neg_Sample):\n",
    "        #    sample['neg'].append(negative())\n",
    "        #sample['neg'] = list(itertools.chain.from_iterable(sample['neg']))\n",
    "        samples = [[sample['pos']],sample['neg']]\n",
    "        samples = list(itertools.chain.from_iterable(samples))\n",
    "        return samples\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.data.shape[0])\n",
    "\n",
    "hole_data = CustomDataset('./Data/train.csv')\n",
    "\n",
    "# Collage function to handle lists in dataloader\n",
    "def my_collate(batch):\n",
    "    #print len(batch)\n",
    "    batch = list(itertools.chain.from_iterable(batch))\n",
    "    data = [item for item in batch]\n",
    "    return data\n",
    "\n",
    "dataloader = DataLoader(hole_data, batch_size=Batch_Size,shuffle=False,collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([25]), tensor([125]), tensor([1]), tensor([[1]])],\n",
       " [tensor([25]), tensor([306]), tensor([1]), tensor([[0]])],\n",
       " [tensor([153]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([17]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([180]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([5]), tensor([1]), tensor([[0]])],\n",
       " [tensor([182]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([140]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([3]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([144]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([111]), tensor([1]), tensor([[0]])],\n",
       " [tensor([91]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([278]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([153]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([12]), tensor([1]), tensor([[0]])],\n",
       " [tensor([268]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([297]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([312]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([221]), tensor([1]), tensor([[0]])],\n",
       " [tensor([308]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([62]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([171]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([66]), tensor([1]), tensor([[0]])],\n",
       " [tensor([185]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([51]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([94]), tensor([1]), tensor([[0]])],\n",
       " [tensor([379]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([280]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([205]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([12]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([29]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([21]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([318]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([178]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([108]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([161]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([378]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([172]), tensor([1]), tensor([[0]])],\n",
       " [tensor([25]), tensor([40]), tensor([1]), tensor([[0]])],\n",
       " [tensor([395]), tensor([125]), tensor([1]), tensor([[0]])],\n",
       " [tensor([305]), tensor([125]), tensor([1]), tensor([[0]])]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hole_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "for d in dataloader:\n",
    "    print len(d)\n",
    "    #print \"--\"\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE CPU\n",
      "HoLE(\n",
      "  (ent_embeddings): Embedding(400, 5)\n",
      "  (rel_embeddings): Embedding(4, 5)\n",
      ")\n",
      "Total number of trainable parameters : 2020\n"
     ]
    }
   ],
   "source": [
    "## Holographic Embedding Implemetations\n",
    "\n",
    "class HoLE(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_entity,num_rel, emb_dim):\n",
    "        super(HoLE,self).__init__()\n",
    "        self.ent_embeddings=nn.Embedding(num_entity,emb_dim)\n",
    "        self.rel_embeddings=nn.Embedding(num_rel,emb_dim)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.ent_embeddings.weight.data)\n",
    "        nn.init.xavier_uniform_(self.rel_embeddings.weight.data)\n",
    "    \n",
    "    # Circular correlation\n",
    "    def ccorr(self, a, b):\n",
    "        #print a\n",
    "        #print a.size()\n",
    "        k = torch.rfft(a,1,onesided=False)\n",
    "        t = torch.rfft(b,1,onesided=False)\n",
    "        k = k *torch.FloatTensor([1,-1])\n",
    "        real = (k[:,:,0] * t[:,:,0]) - (k[:,:,1] * t[:,:,1])\n",
    "        imag = (k[:,:,0] * t[:,:,1]) + (k[:,:,1] * t[:,:,0])\n",
    "        a=[]\n",
    "        for i,j in zip(real,imag):\n",
    "            a.append(i)\n",
    "            a.append(j)\n",
    "        a =torch.stack(a,dim=-1)\n",
    "        #print a.size()\n",
    "        t = torch.split(a,2,dim=1)\n",
    "        t = torch.stack(t,dim=0)\n",
    "        #print t.size()\n",
    "        v = torch.ifft(t,1)\n",
    "        #print v.size()\n",
    "        return v[:,:,0]\n",
    "    \n",
    "    def score(self,head, tail, rel):\n",
    "        entity_mention = self.ccorr(head, tail)\n",
    "        relation_norm = rel.norm(p=2, dim=1, keepdim=True)\n",
    "        relation_mention = rel.div(relation_norm.expand_as(rel))\n",
    "        #print relation_mention.size()\n",
    "        #print entity_mention.size()\n",
    "        _sum = torch.sum(relation_mention * entity_mention,dim=1)\n",
    "        #print _sum.size()\n",
    "        return torch.sigmoid(_sum)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #x = Variable(torch.LongTensor(x))\n",
    "        #print x\n",
    "        #print type(x)\n",
    "        entity_a, entity_b, relation = x[:,0].view(-1, 1),x[:,1].view(-1, 1),x[:,2].view(-1, 1)\n",
    "        s = self.ent_embeddings(entity_a)\n",
    "        #print entity_b\n",
    "        o = self.ent_embeddings(entity_b)\n",
    "        r = self.rel_embeddings(relation)\n",
    "        #print s.view(-1,10).size()\n",
    "        #print o.size()\n",
    "        #print r.size()\n",
    "        out = self.score(s.view(-1,emb_dim),o.view(-1,emb_dim),r.view(-1,emb_dim))\n",
    "        return out\n",
    "\n",
    "## Loading the model\n",
    "num_entity = Total_Entities\n",
    "num_relation = Total_Relations\n",
    "emb_dim =5\n",
    "\n",
    "hole = HoLE(num_entity,num_relation,emb_dim)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    hole = hole.cuda()\n",
    "    print ('USE GPU')\n",
    "else:\n",
    "    print ('USE CPU')\n",
    "print hole\n",
    "\n",
    "# Total number of trainable parameters\n",
    "total_params = sum(p.numel() for p in hole.parameters() if p.requires_grad)\n",
    "print(\"Total number of trainable parameters : {}\" .format(total_params))\n",
    "\n",
    "# Criterion and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(hole.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.LBFGS(hole.parameters(), lr=0.001)\n",
    "\n",
    "# train and validation losses\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "# Training of model\n",
    "num_epoch = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n",
      "Epoch [1/40]train Loss: 0.6929\n",
      "Epoch 1/39\n",
      "----------\n",
      "Epoch [2/40]train Loss: 0.6894\n",
      "Epoch 2/39\n",
      "----------\n",
      "Epoch [3/40]train Loss: 0.6690\n",
      "Epoch 3/39\n",
      "----------\n",
      "Epoch [4/40]train Loss: 0.6221\n",
      "Epoch 4/39\n",
      "----------\n",
      "Epoch [5/40]train Loss: 0.5564\n",
      "Epoch 5/39\n",
      "----------\n",
      "Epoch [6/40]train Loss: 0.4814\n",
      "Epoch 6/39\n",
      "----------\n",
      "Epoch [7/40]train Loss: 0.4096\n",
      "Epoch 7/39\n",
      "----------\n",
      "Epoch [8/40]train Loss: 0.3464\n",
      "Epoch 8/39\n",
      "----------\n",
      "Epoch [9/40]train Loss: 0.2923\n",
      "Epoch 9/39\n",
      "----------\n",
      "Epoch [10/40]train Loss: 0.2503\n",
      "Epoch 10/39\n",
      "----------\n",
      "Epoch [11/40]train Loss: 0.2160\n",
      "Epoch 11/39\n",
      "----------\n",
      "Epoch [12/40]train Loss: 0.1892\n",
      "Epoch 12/39\n",
      "----------\n",
      "Epoch [13/40]train Loss: 0.1697\n",
      "Epoch 13/39\n",
      "----------\n",
      "Epoch [14/40]train Loss: 0.1543\n",
      "Epoch 14/39\n",
      "----------\n",
      "Epoch [15/40]train Loss: 0.1424\n",
      "Epoch 15/39\n",
      "----------\n",
      "Epoch [16/40]train Loss: 0.1333\n",
      "Epoch 16/39\n",
      "----------\n",
      "Epoch [17/40]train Loss: 0.1269\n",
      "Epoch 17/39\n",
      "----------\n",
      "Epoch [18/40]train Loss: 0.1222\n",
      "Epoch 18/39\n",
      "----------\n",
      "Epoch [19/40]train Loss: 0.1184\n",
      "Epoch 19/39\n",
      "----------\n",
      "Epoch [20/40]train Loss: 0.1157\n",
      "Epoch 20/39\n",
      "----------\n",
      "Epoch [21/40]train Loss: 0.1134\n",
      "Epoch 21/39\n",
      "----------\n",
      "Epoch [22/40]train Loss: 0.1121\n",
      "Epoch 22/39\n",
      "----------\n",
      "Epoch [23/40]train Loss: 0.1105\n",
      "Epoch 23/39\n",
      "----------\n",
      "Epoch [24/40]train Loss: 0.1098\n",
      "Epoch 24/39\n",
      "----------\n",
      "Epoch [25/40]train Loss: 0.1089\n",
      "Epoch 25/39\n",
      "----------\n",
      "Epoch [26/40]train Loss: 0.1082\n",
      "Epoch 26/39\n",
      "----------\n",
      "Epoch [27/40]train Loss: 0.1080\n",
      "Epoch 27/39\n",
      "----------\n",
      "Epoch [28/40]train Loss: 0.1071\n",
      "Epoch 28/39\n",
      "----------\n",
      "Epoch [29/40]train Loss: 0.1064\n",
      "Epoch 29/39\n",
      "----------\n",
      "Epoch [30/40]train Loss: 0.1060\n",
      "Epoch 30/39\n",
      "----------\n",
      "Epoch [31/40]train Loss: 0.1057\n",
      "Epoch 31/39\n",
      "----------\n",
      "Epoch [32/40]train Loss: 0.1052\n",
      "Epoch 32/39\n",
      "----------\n",
      "Epoch [33/40]train Loss: 0.1045\n",
      "Epoch 33/39\n",
      "----------\n",
      "Epoch [34/40]train Loss: 0.1044\n",
      "Epoch 34/39\n",
      "----------\n",
      "Epoch [35/40]train Loss: 0.1041\n",
      "Epoch 35/39\n",
      "----------\n",
      "Epoch [36/40]train Loss: 0.1039\n",
      "Epoch 36/39\n",
      "----------\n",
      "Epoch [37/40]train Loss: 0.1034\n",
      "Epoch 37/39\n",
      "----------\n",
      "Epoch [38/40]train Loss: 0.1030\n",
      "Epoch 38/39\n",
      "----------\n",
      "Epoch [39/40]train Loss: 0.1029\n",
      "Epoch 39/39\n",
      "----------\n",
      "Epoch [40/40]train Loss: 0.1026\n"
     ]
    }
   ],
   "source": [
    "for epoch in range( num_epoch):\n",
    "    \n",
    "    print('Epoch {}/{}'.format(epoch, num_epoch- 1))\n",
    "    print('-' * 10)\n",
    "    \n",
    "    # Each epoch has a training \n",
    "    hole.train() # Set model to training mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    # Iterate over data.\n",
    "    for idx,x in enumerate(dataloader):\n",
    "        x = Variable(torch.LongTensor(x))\n",
    "        if use_gpu:\n",
    "            x  = x.cuda()\n",
    "\n",
    "        #print x.size()\n",
    "        outputs = hole(x) # Forward pass: compute the output class given a image\n",
    "        target = x[:,3].view(-1, 1)\n",
    "        target = target.type(torch.FloatTensor)\n",
    "        optimizer.zero_grad() # clear gradients for next train\n",
    "        outputs = outputs.view(-1,1)\n",
    "        loss = criterion(outputs,target) # Compute the loss: difference between the output class and the pre-given label\n",
    "        loss.backward() # backpropagation, compute gradients\n",
    "        optimizer.step() # apply gradients  and update the weights of hidden nodes\n",
    "\n",
    "        running_loss += loss.data * outputs.shape[0]\n",
    "\n",
    "        #if phase == 'train':\n",
    "        #    if (i+1) % 100 == 0 :\n",
    "        #        print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' %(epoch+1, num_epoch, i+1, data_lengths[phase]//64, loss.data))\n",
    "\n",
    "    epoch_loss = running_loss/float((train_data.shape[0]*Num_Neg_Sample)+train_data.shape[0]) \n",
    "    train_losses.append(epoch_loss)\n",
    "    print('Epoch [{}/{}]{} Loss: {:.4f}'.format(epoch+1, num_epoch,'train', epoch_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAF3CAYAAAC8MNLCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4f225df4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(8, 6),)\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93e72d1eaee43478cb9d2c66cbe5fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction function\n",
    "def hole_prediction(model,fact):\n",
    "    model.eval()\n",
    "    i = fact['entity_a']\n",
    "    j = fact['entity_b']\n",
    "    r = fact['relation']\n",
    "    xt = [torch.LongTensor([i]),torch.LongTensor([j]),torch.LongTensor([r])]\n",
    "    xt = Variable(torch.LongTensor(xt))\n",
    "    xt = xt.view(1,-1)\n",
    "    pred_score = hole(xt)\n",
    "    if pred_score.data>0.5:\n",
    "        return pred_score.data, 1\n",
    "    else:\n",
    "        return pred_score.data, 0\n",
    "\n",
    "## Training Data Stats\n",
    "\n",
    "train_data =  pd.read_csv('./Data/train.csv', delimiter=',')\n",
    "train_data.dropna(inplace=True)\n",
    "train_data['prediction'] = ''\n",
    "# Calculating train data stats\n",
    "for idx,dat in  tqdm.tqdm_notebook(enumerate(train_data.iterrows())):\n",
    "    train_data['prediction'].iloc[idx],_ = hole_prediction(hole,dat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_a</th>\n",
       "      <th>entity_b</th>\n",
       "      <th>relation</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.0368)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0405)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>326</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0293)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>339</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0377)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198</td>\n",
       "      <td>298</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0419)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>165</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0321)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>314</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0284)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>101</td>\n",
       "      <td>201</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0342)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.0316)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>117</td>\n",
       "      <td>317</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0444)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>301</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0451)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>56</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.0480)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.0337)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>213</td>\n",
       "      <td>313</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0404)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>183</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0555)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0510)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>97</td>\n",
       "      <td>397</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0379)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>263</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0643)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>168</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0654)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>345</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0446)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>286</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0446)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>104</td>\n",
       "      <td>204</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0291)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>85</td>\n",
       "      <td>385</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0343)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>384</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0422)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0642)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>114</td>\n",
       "      <td>214</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0210)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19</td>\n",
       "      <td>319</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0541)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0515)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>149</td>\n",
       "      <td>249</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0290)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.0538)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>89</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.0452)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>196</td>\n",
       "      <td>296</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0375)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>120</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0299)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>176</td>\n",
       "      <td>376</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0397)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>160</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0282)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>181</td>\n",
       "      <td>381</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0375)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.0189)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>92</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.0168)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>117</td>\n",
       "      <td>217</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0445)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>81</td>\n",
       "      <td>381</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0399)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>180</td>\n",
       "      <td>380</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0411)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>28</td>\n",
       "      <td>328</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0437)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>42</td>\n",
       "      <td>342</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0451)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>152</td>\n",
       "      <td>352</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0334)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>238</td>\n",
       "      <td>338</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0444)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>95</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.0370)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>112</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0383)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>110</td>\n",
       "      <td>310</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0407)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>108</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0458)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>102</td>\n",
       "      <td>202</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0316)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>12</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0420)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>249</td>\n",
       "      <td>349</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0454)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>138</td>\n",
       "      <td>338</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0397)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>144</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0.0315)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>99</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(0.0325)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>255</td>\n",
       "      <td>355</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0377)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>258</td>\n",
       "      <td>358</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0354)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>76</td>\n",
       "      <td>376</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0413)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>144</td>\n",
       "      <td>344</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0361)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>31</td>\n",
       "      <td>331</td>\n",
       "      <td>3</td>\n",
       "      <td>[tensor(0.0677)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     entity_a  entity_b  relation        prediction\n",
       "0          25       125         1  [tensor(0.0368)]\n",
       "1         187       100         0  [tensor(0.0405)]\n",
       "2         226       326         3  [tensor(0.0293)]\n",
       "3          39       339         3  [tensor(0.0377)]\n",
       "4         198       298         2  [tensor(0.0419)]\n",
       "5         165       265         2  [tensor(0.0321)]\n",
       "6         314       300         0  [tensor(0.0284)]\n",
       "7         101       201         2  [tensor(0.0342)]\n",
       "8          33       133         1  [tensor(0.0316)]\n",
       "9         117       317         3  [tensor(0.0444)]\n",
       "10        301       300         0  [tensor(0.0451)]\n",
       "11         56       156         1  [tensor(0.0480)]\n",
       "12         21       121         1  [tensor(0.0337)]\n",
       "13        213       313         3  [tensor(0.0404)]\n",
       "14        183       100         0  [tensor(0.0555)]\n",
       "15         95         0         0  [tensor(0.0510)]\n",
       "16         97       397         3  [tensor(0.0379)]\n",
       "17        263       200         0  [tensor(0.0643)]\n",
       "18        168       100         0  [tensor(0.0654)]\n",
       "19        345       300         0  [tensor(0.0446)]\n",
       "20        286       200         0  [tensor(0.0446)]\n",
       "21        104       204         2  [tensor(0.0291)]\n",
       "22         85       385         3  [tensor(0.0343)]\n",
       "23        384       300         0  [tensor(0.0422)]\n",
       "24        101       100         0  [tensor(0.0642)]\n",
       "25        114       214         2  [tensor(0.0210)]\n",
       "26         19       319         3  [tensor(0.0541)]\n",
       "27         94         0         0  [tensor(0.0515)]\n",
       "28        149       249         2  [tensor(0.0290)]\n",
       "29         45         0         0  [tensor(0.0538)]\n",
       "..        ...       ...       ...               ...\n",
       "363        89       189         1  [tensor(0.0452)]\n",
       "364       196       296         2  [tensor(0.0375)]\n",
       "365       120       220         2  [tensor(0.0299)]\n",
       "366       176       376         3  [tensor(0.0397)]\n",
       "367       160       260         2  [tensor(0.0282)]\n",
       "368       181       381         3  [tensor(0.0375)]\n",
       "369         7       107         1  [tensor(0.0189)]\n",
       "370        92       192         1  [tensor(0.0168)]\n",
       "371       117       217         2  [tensor(0.0445)]\n",
       "372        81       381         3  [tensor(0.0399)]\n",
       "373       180       380         3  [tensor(0.0411)]\n",
       "374        28       328         3  [tensor(0.0437)]\n",
       "375        42       342         3  [tensor(0.0451)]\n",
       "376       152       352         3  [tensor(0.0334)]\n",
       "377       238       338         3  [tensor(0.0444)]\n",
       "378        95       195         1  [tensor(0.0370)]\n",
       "379       112       312         3  [tensor(0.0383)]\n",
       "380       110       310         3  [tensor(0.0407)]\n",
       "381       108       208         2  [tensor(0.0458)]\n",
       "382       102       202         2  [tensor(0.0316)]\n",
       "383        12       312         3  [tensor(0.0420)]\n",
       "384       249       349         3  [tensor(0.0454)]\n",
       "385       138       338         3  [tensor(0.0397)]\n",
       "386       144       244         2  [tensor(0.0315)]\n",
       "387        99       199         1  [tensor(0.0325)]\n",
       "388       255       355         3  [tensor(0.0377)]\n",
       "389       258       358         3  [tensor(0.0354)]\n",
       "390        76       376         3  [tensor(0.0413)]\n",
       "391       144       344         3  [tensor(0.0361)]\n",
       "392        31       331         3  [tensor(0.0677)]\n",
       "\n",
       "[393 rows x 4 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afed6a0615b4645ac1e0e48d8892565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "- - - - - - - - - - - - - STATISTICS ON TRAINING DATASET - - - - - - - - - - - - - - \n",
      "\n",
      "Total number of Green links in training dataset : 393 \n",
      " Number of Green predicted correctly: 77\n",
      " Accuracy of Green predicted correctly: 0.195928753181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d00d65059bc4e738326bbe1706ae173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "- - - - - - - - - - - - - STATISTICS ON VALIDATION DATASET - - - - - - - - - - - - - - \n",
      "\n",
      "Total number of Green links in training dataset : 124 \n",
      " Number of Green predicted correctly: 12\n",
      " Accuracy of Green predicted correctly: 0.0967741935484\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec746301cac043c2960f094af35c8330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "- - - - - - - - - - - - - STATISTICS ON TO_USE DATASET - - - - - - - - - - - - - - \n",
      "\n",
      "Total number of Green links in training dataset : 374 \n",
      " Number of Green predicted correctly: 27\n",
      " Accuracy of Green predicted correctly: 0.072192513369\n"
     ]
    }
   ],
   "source": [
    "# prediction function\n",
    "def hole_prediction(model,fact):\n",
    "    model.eval()\n",
    "    i = fact['entity_a']\n",
    "    j = fact['entity_b']\n",
    "    score = -1\n",
    "    for k in range(4):\n",
    "        xt = [torch.LongTensor([i]),torch.LongTensor([j]),torch.LongTensor([k])]\n",
    "        xt = Variable(torch.LongTensor(xt))\n",
    "        xt = xt.view(1,-1)\n",
    "        #print xt.size()\n",
    "        #print \"predicting\"\n",
    "        pred_score = hole(xt)\n",
    "        #print pred_score\n",
    "        if score < pred_score.data:\n",
    "            prediction = k\n",
    "            score = pred_score.data\n",
    "    return score, prediction\n",
    "\n",
    "## Training Data Stats\n",
    "\n",
    "train_data =  pd.read_csv('./Data/train.csv', delimiter=',')\n",
    "train_data.dropna(inplace=True)\n",
    "train_data['prediction'] = ''\n",
    "# Calculating train data stats\n",
    "for idx,dat in  tqdm.tqdm_notebook(enumerate(train_data.iterrows())):\n",
    "    _,train_data['prediction'].iloc[idx] = hole_prediction(hole,dat[1])\n",
    "\n",
    "acc_count = (train_data['prediction'] == train_data['relation']).sum()\n",
    "acc = float(acc_count)/train_data.shape[0]\n",
    "\n",
    "# Printing results\n",
    "print(\"\\n- - - - - - - - - - - - - STATISTICS ON TRAINING DATASET - - - - - - - - - - - - - - \\n\")\n",
    "print(\"Total number of Green links in training dataset : {} \".format(train_data.shape[0]))\n",
    "print(\" Number of Green predicted correctly: {}\".format(acc_count))\n",
    "print(\" Accuracy of Green predicted correctly: {}\".format(acc))\n",
    "\n",
    "## Validation Data Stats\n",
    "\n",
    "valid_data =  pd.read_csv('./Data/valid.csv', delimiter=',')\n",
    "valid_data.dropna(inplace=True)\n",
    "valid_data['prediction'] = ''\n",
    "# Calculating train data stats\n",
    "for idx,dat in  tqdm.tqdm_notebook(enumerate(valid_data.iterrows())):\n",
    "    _,valid_data['prediction'].iloc[idx] = hole_prediction(hole,dat[1])\n",
    "\n",
    "acc_count = (valid_data['prediction'] == valid_data['relation']).sum()\n",
    "acc = float(acc_count)/valid_data.shape[0]\n",
    "\n",
    "# Printing results\n",
    "print(\"\\n- - - - - - - - - - - - - STATISTICS ON VALIDATION DATASET - - - - - - - - - - - - - - \\n\")\n",
    "print(\"Total number of Green links in training dataset : {} \".format(valid_data.shape[0]))\n",
    "print(\" Number of Green predicted correctly: {}\".format(acc_count))\n",
    "print(\" Accuracy of Green predicted correctly: {}\".format(acc))\n",
    "\n",
    "## To_use Data Stats\n",
    "\n",
    "test_data =  pd.read_csv('./Data/to_use.csv', delimiter=',')\n",
    "test_data.dropna(inplace=True)\n",
    "test_data['prediction'] = ''\n",
    "# Calculating train data stats\n",
    "for idx,dat in  tqdm.tqdm_notebook(enumerate(test_data.iterrows())):\n",
    "    _,test_data['prediction'].iloc[idx] = hole_prediction(hole,dat[1])\n",
    "\n",
    "acc_count = (test_data['prediction'] == test_data['relation']).sum()\n",
    "acc = float(acc_count)/test_data.shape[0]\n",
    "\n",
    "# Printing results\n",
    "print(\"\\n- - - - - - - - - - - - - STATISTICS ON TO_USE DATASET - - - - - - - - - - - - - - \\n\")\n",
    "print(\"Total number of Green links in training dataset : {} \".format(test_data.shape[0]))\n",
    "print(\" Number of Green predicted correctly: {}\".format(acc_count))\n",
    "print(\" Accuracy of Green predicted correctly: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
